{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597667780156",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 Physical GPUs, 1 Logical GPUs\nUsing TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Memory Allocation for using GPU \n",
    "import tensorflow as tf \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Dropout, Reshape, Permute, Activation, ZeroPadding2D, Cropping2D, Add\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, DepthwiseConv2D\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential # using Sequential\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Data Shape: (12706, 256, 256, 3)\nValidation Data Shape: (5000, 256, 256, 3)\n"
    }
   ],
   "source": [
    "DATA_PATH = os.path.abspath(\"..\\\\..\\\\00_MLDL\\\\00_BreadBrother\\\\05_Human_Segmentation\")\n",
    "\n",
    "IMG_H = 256\n",
    "IMG_W = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "x_train = np.load(os.path.join(DATA_PATH, \"preprocessed_dataset\\\\x_train.npz\"))['data'].astype(np.float32) # 12706, 256, 256, 3\n",
    "y_train = np.load(os.path.join(DATA_PATH, \"preprocessed_dataset\\\\y_train.npz\"))['data'].astype(np.float32) # 12706, 256, 256, 2\n",
    "\n",
    "x_val = np.load(os.path.join(DATA_PATH, \"preprocessed_dataset\\\\x_val.npz\"))['data'].astype(np.float32) # 5000, 256, 256, 3\n",
    "y_val = np.load(os.path.join(DATA_PATH, \"preprocessed_dataset\\\\y_val.npz\"))['data'].astype(np.float32) # 5000, 256, 256, 2 : why 2-ch? using softmax, 1st ch : human 0, 2nd ch :human 1\n",
    "# for customize, using 2nd channel\n",
    "\n",
    "print(f\"Training Data Shape: {x_train.shape}\")\n",
    "print(f\"Validation Data Shape: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255., # normalize 0~1\n",
    "    brightness_range=[0.7, 1.3] # Data Augmentation\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(IMG_H, IMG_W, 3))\n",
    "\n",
    "# Encode\n",
    "conv1_1 = Conv2D(32, kernel_size=3, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(inputs) # Output shape (256,256,32)\n",
    "# conv1_1 = Dorpout(0.2)(conv1_1)\n",
    "conv1_2 = Conv2D(64, kernel_size=3, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(conv1_1) # Output shape (256,256,64)\n",
    "pool1 = MaxPooling2D(pool_size=2)(conv1_2) # Output shape (128,128,64)\n",
    "\n",
    "shortcut_1 = pool1\n",
    "\n",
    "conv2_1 = Conv2D(64, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(pool1) # Output shape (128, 128, 64)\n",
    "# conv2_1 = Dorpout(0.2)(conv2_!)\n",
    "conv2_2 = Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(conv2_1)\n",
    "# Output shape (128, 128, 128)\n",
    "pool2 = MaxPooling2D(pool_size=2)(conv2_2) # Output shape (64, 64, 128)\n",
    "\n",
    "shortcut_2 = pool2\n",
    "\n",
    "conv3_1 = Conv2D(128, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(pool2) # Output shape (64, 64, 128)\n",
    "# conv3_1 = Dropout(0.2)(conv3_1)\n",
    "conv3_2 = Conv2D(256, 3, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(conv3_1)# Output shape (64, 64, 256)\n",
    "pool3 = MaxPooling2D(pool_size=2)(conv3_2) # Output shape(32, 32, 256)\n",
    "\n",
    "shortcut_3 = pool3\n",
    "\n",
    "mid_1 = DepthwiseConv2D(3, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(pool3) # Output shape (32, 32, 256)\n",
    "mid_2 = Conv2D(256, 1, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(mid_1) # Output shape (32, 32, 256)\n",
    "mid_3 = DepthwiseConv2D(3, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(mid_2) # Output shape (32, 32, 256)\n",
    "mid_4 = Conv2D(256, 1, activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")(mid_3) # Output shape (32, 32, 256)\n",
    "\n",
    "mid_5 = Add()([shortcut_3, mid_4]) # (32,32,256) + (32,32,256) = (32,32,256)\n",
    "\n",
    "# Decode\n",
    "up8_1 = UpSampling2D(size=2)(mid_5) # Output shape (64, 64, 256)\n",
    "up8_2 = concatenate([up8_1, conv3_2], axis=-1) # (64,64,256) + (64,64,256) = (64, 64, 512)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}